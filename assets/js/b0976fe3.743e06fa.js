"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3245],{5213:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"Code-Documentation/Description","title":"Documentation","description":"1. Data Description","source":"@site/docs/Code-Documentation/Description.md","sourceDirName":"Code-Documentation","slug":"/Code-Documentation/Description","permalink":"/agrichat-annam/docs/Code-Documentation/Description","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Code-Documentation/Description.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Code Documentation","permalink":"/agrichat-annam/docs/category/code-documentation"},"next":{"title":"Technical Code Walkthrough","permalink":"/agrichat-annam/docs/Code-Documentation/technical-walkthrough"}}');var t=i(4848),r=i(8453);const a={},l="Documentation",d={},o=[{value:"1. Data Description",id:"1-data-description",level:2},{value:"2. Data Preprocessing",id:"2-data-preprocessing",level:2},{value:"2.1 Cleaning and Filtering",id:"21-cleaning-and-filtering",level:3},{value:"2.2 Semantic Deduplication",id:"22-semantic-deduplication",level:3},{value:"3. Chunking Strategy",id:"3-chunking-strategy",level:2},{value:"Why Not Semantic or Agentic Chunking?",id:"why-not-semantic-or-agentic-chunking",level:3},{value:"Benefits of Row-based Chunking:",id:"benefits-of-row-based-chunking",level:3},{value:"4. Vector Embedding Generation",id:"4-vector-embedding-generation",level:2},{value:"Embedding Engine",id:"embedding-engine",level:3},{value:"Embedding Workflow",id:"embedding-workflow",level:3},{value:"Advantages",id:"advantages",level:3},{value:"5. Vector Database Storage",id:"5-vector-database-storage",level:2},{value:"Technology",id:"technology",level:3},{value:"Storage Structure",id:"storage-structure",level:3},{value:"Persistent Storage",id:"persistent-storage",level:3},{value:"6. Semantic Retrieval Mechanism",id:"6-semantic-retrieval-mechanism",level:2},{value:"Retrieval Workflow",id:"retrieval-workflow",level:3},{value:"Benefits",id:"benefits",level:3},{value:"7. Prompt Construction &amp; LLM Response Generation",id:"7-prompt-construction--llm-response-generation",level:2},{value:"LLM Engine",id:"llm-engine",level:3},{value:"Prompt Design",id:"prompt-design",level:3},{value:"Special Handling",id:"special-handling",level:3},{value:"8. FastAPI Web Application Interface",id:"8-fastapi-web-application-interface",level:2},{value:"Features",id:"features",level:3},{value:"UI Enhancements",id:"ui-enhancements",level:3}];function c(e){const n={a:"a",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"documentation",children:"Documentation"})}),"\n",(0,t.jsx)(n.h2,{id:"1-data-description",children:"1. Data Description"}),"\n",(0,t.jsxs)(n.p,{children:["The dataset used in this system originates from ",(0,t.jsx)(n.a,{href:"https://data.gov.in",children:"data.gov.in"})," and contains interaction logs from the ",(0,t.jsx)(n.strong,{children:"Kisan Call Centre"}),", where farmers call to ask agricultural queries and receive guidance from trained experts."]}),"\n",(0,t.jsx)(n.p,{children:"The dataset includes two primary columns:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"questions"}),": Queries asked by farmers"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"answers"}),": Responses provided by agricultural experts"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The initial dataset consists of ",(0,t.jsx)(n.strong,{children:"178,939 rows"})," and ",(0,t.jsx)(n.strong,{children:"2 columns"}),". However, for optimal performance and relevance, a robust data preprocessing strategy is applied to refine the dataset prior to ingestion into the RAG pipeline."]}),"\n",(0,t.jsx)(n.h2,{id:"2-data-preprocessing",children:"2. Data Preprocessing"}),"\n",(0,t.jsx)(n.h3,{id:"21-cleaning-and-filtering",children:"2.1 Cleaning and Filtering"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Handling Missing Values"}),": All rows with null or missing entries in the questions or answers fields were removed to maintain dataset consistency."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Filtering Non-informative Entries"}),": Rows containing generic phrases, administrative notes (e.g., \u201ccall transferred to expert\u201d, \u201cTest Call\u201d), numeric-only content, or placeholders (e.g., \u201c--\u201d) were excluded."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Whitespace & Casing Normalization"}),": All text was lowercased and stripped of unnecessary spacing."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"22-semantic-deduplication",children:"2.2 Semantic Deduplication"}),"\n",(0,t.jsxs)(n.p,{children:["Traditional string-based deduplication approaches (e.g., ",(0,t.jsx)(n.code,{children:"pandas.drop_duplicates()"}),") were found insufficient, as they failed to detect semantically similar but textually different entries."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Method:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Each question and answer were concatenated into a single field: ",(0,t.jsx)(n.code,{children:"qa_combined"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Embeddings were generated using the ",(0,t.jsx)(n.strong,{children:"all-MiniLM-L6-v2"})," model via the ",(0,t.jsx)(n.strong,{children:"sentence-transformers"})," library."]}),"\n",(0,t.jsx)(n.li,{children:"Cosine similarity was computed pairwise between all question-answer pairs."}),"\n",(0,t.jsxs)(n.li,{children:["Any pair of rows with a similarity score exceeding ",(0,t.jsx)(n.strong,{children:"0.95"})," were deemed semantically redundant, and one of them was removed."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Outcome:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"This approach significantly reduced redundancy, resulting in a more informative and diverse dataset, suitable for semantic search-based retrieval tasks."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"3-chunking-strategy",children:"3. Chunking Strategy"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Final Strategy"}),": ",(0,t.jsx)(n.strong,{children:"Row-Based Q&A Chunking"})]}),"\n",(0,t.jsx)(n.p,{children:"Each row in the dataset\u2014representing a single question-answer pair\u2014is treated as a standalone document. This method offered the best balance between granularity, semantic coherence, and alignment with the intended use case."}),"\n",(0,t.jsx)(n.h3,{id:"why-not-semantic-or-agentic-chunking",children:"Why Not Semantic or Agentic Chunking?"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Semantic Chunking"}),": Often merged answer parts with unrelated questions, diluting retrieval quality."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Agentic Chunking"}),": Risked overly large documents, sometimes exceeding model input limits."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"benefits-of-row-based-chunking",children:"Benefits of Row-based Chunking:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Ensures high semantic fidelity by associating a query directly with its answer."}),"\n",(0,t.jsxs)(n.li,{children:["Aligns with LangChain\u2019s ",(0,t.jsx)(n.code,{children:"CSVLoader"}),", which naturally loads documents row-wise."]}),"\n",(0,t.jsx)(n.li,{children:"Guarantees that retrieval focuses on complete, contextually relevant Q&A blocks."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"4-vector-embedding-generation",children:"4. Vector Embedding Generation"}),"\n",(0,t.jsx)(n.p,{children:"To support semantic retrieval, each document (Q&A pair) is transformed into a dense vector using a transformer model."}),"\n",(0,t.jsx)(n.h3,{id:"embedding-engine",children:"Embedding Engine"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Embeddings are generated using ",(0,t.jsxs)(n.strong,{children:["nomic-embed-text",":latest"]}),", hosted locally via ",(0,t.jsx)(n.strong,{children:"Ollama"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["A custom embedding interface (",(0,t.jsx)(n.code,{children:"OllamaEmbeddings"}),") manages all interactions with the local embedding server."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"embedding-workflow",children:"Embedding Workflow"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Each document (row) is passed to the embedding client."}),"\n",(0,t.jsx)(n.li,{children:"Embeddings are generated and batched efficiently."}),"\n",(0,t.jsx)(n.li,{children:"All document vectors are stored persistently in a local vector database."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"advantages",children:"Advantages"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Privacy"}),": No third-party APIs involved."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Speed"}),": Local inference using GPU or CPU."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Flexibility"}),": Future fine-tuned or custom models can be integrated easily."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"5-vector-database-storage",children:"5. Vector Database Storage"}),"\n",(0,t.jsx)(n.p,{children:"The vector database is responsible for storing document embeddings and enabling high-speed semantic similarity searches."}),"\n",(0,t.jsx)(n.h3,{id:"technology",children:"Technology"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ChromaDB"})," is used as the vector store for its performance, persistence support, and compatibility with LangChain."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"storage-structure",children:"Storage Structure"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Page content"}),": Combined Q&A string"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Embedding"}),": Generated via Ollama"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Metadata"}),": Includes row number, and optionally crop/category"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"persistent-storage",children:"Persistent Storage"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"ChromaDB is initialized with a specified directory to ensure that embeddings are saved between sessions. This avoids the need to recompute embeddings on system restart."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"6-semantic-retrieval-mechanism",children:"6. Semantic Retrieval Mechanism"}),"\n",(0,t.jsx)(n.p,{children:"At inference time, the RAG pipeline retrieves the most semantically relevant Q&A pairs to serve as context for the LLM."}),"\n",(0,t.jsx)(n.h3,{id:"retrieval-workflow",children:"Retrieval Workflow"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Query Embedding"}),":",(0,t.jsx)(n.br,{}),"\n","The user\u2019s question is embedded using the same ",(0,t.jsx)(n.code,{children:"nomic-embed-text:latest"})," model for consistency."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Initial Retrieval (k=10)"}),":",(0,t.jsx)(n.br,{}),"\n","ChromaDB performs a similarity search to retrieve the top 10 semantically similar chunks."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Cosine Reranking"}),":",(0,t.jsx)(n.br,{}),"\n","Retrieved documents are reranked using cosine similarity between the query embedding and the document embedding."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Final Context Selection (Top 5)"}),":",(0,t.jsx)(n.br,{}),"\n","The top 5 most relevant documents post-reranking are selected for the final prompt context."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Filtering Threshold"}),":",(0,t.jsx)(n.br,{}),"\n","A similarity threshold (e.g., 0.5) is applied to discard irrelevant matches."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"benefits",children:"Benefits"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Balances recall and precision by combining wide-net retrieval and fine-grained reranking."}),"\n",(0,t.jsx)(n.li,{children:"Prevents overfitting to irrelevant phrases or answer fragments."}),"\n",(0,t.jsx)(n.li,{children:"Ensures that only semantically closest documents are passed to the LLM."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"7-prompt-construction--llm-response-generation",children:"7. Prompt Construction & LLM Response Generation"}),"\n",(0,t.jsx)(n.p,{children:"Once the relevant context is retrieved, it is combined with the user\u2019s query and inserted into a structured prompt for the LLM to process."}),"\n",(0,t.jsx)(n.h3,{id:"llm-engine",children:"LLM Engine"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The chosen model is ",(0,t.jsx)(n.strong,{children:"gemma3:27b"}),", hosted locally via ",(0,t.jsx)(n.strong,{children:"Ollama"}),"."]}),"\n",(0,t.jsx)(n.li,{children:"All LLM interaction is performed through an OpenAI-compatible API interface."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"prompt-design",children:"Prompt Design"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-plaintext",children:"You are an AI assistant for agricultural advisory...\r\n\r\nContext:\r\n{top_5_documents_combined}\r\n\r\nQuestion:\r\n{user_query}\r\n\r\nAnswer:\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Encourages factual synthesis from context."}),"\n",(0,t.jsx)(n.li,{children:"Instructs the model to avoid hallucinations."}),"\n",(0,t.jsxs)(n.li,{children:["Includes a fallback response:",(0,t.jsx)(n.br,{}),"\n",(0,t.jsx)(n.em,{children:"\u201cI don't have enough information to answer that.\u201d"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"special-handling",children:"Special Handling"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["If the model outputs a ",(0,t.jsx)(n.code,{children:"<think>...</think>"})," reasoning block, only the content after ",(0,t.jsx)(n.code,{children:"</think>"})," is rendered in the UI."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"8-fastapi-web-application-interface",children:"8. FastAPI Web Application Interface"}),"\n",(0,t.jsxs)(n.p,{children:["A user-friendly interface is served using ",(0,t.jsx)(n.strong,{children:"FastAPI"})," + ",(0,t.jsx)(n.strong,{children:"Jinja2"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"features",children:"Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Query submission form"}),"\n",(0,t.jsx)(n.li,{children:"Clean UI with CSS-styled markdown rendering"}),"\n",(0,t.jsx)(n.li,{children:"Responses displayed in bullet or paragraph format"}),"\n",(0,t.jsx)(n.li,{children:"Logs both markdown and HTML output to terminal for debugging"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"ui-enhancements",children:"UI Enhancements"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["HTML output rendered from markdown using the ",(0,t.jsx)(n.code,{children:"markdown"})," module"]}),"\n",(0,t.jsx)(n.li,{children:"Responsive design"}),"\n",(0,t.jsx)(n.li,{children:"Structured presentation of diseases, symptoms, and treatments"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>l});var s=i(6540);const t={},r=s.createContext(t);function a(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);