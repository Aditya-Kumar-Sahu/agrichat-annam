"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4150],{5488:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>h,frontMatter:()=>i,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"Code-Documentation/technical-walkthrough","title":"Technical Code Walkthrough","description":"---","source":"@site/docs/Code-Documentation/technical-walkthrough.md","sourceDirName":"Code-Documentation","slug":"/Code-Documentation/technical-walkthrough","permalink":"/agrichat-annam/docs/Code-Documentation/technical-walkthrough","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Code-Documentation/technical-walkthrough.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Documentation","permalink":"/agrichat-annam/docs/Code-Documentation/Description"},"next":{"title":"Troubleshooting","permalink":"/agrichat-annam/docs/troubleshooting/"}}');var a=s(4848),t=s(8453);const i={},l="Technical Code Walkthrough",d={},o=[{value:"1. Data Preprocessing",id:"1-data-preprocessing",level:2},{value:"a. Loading Data",id:"a-loading-data",level:3},{value:"b. Handling Missing and Non-informative Values",id:"b-handling-missing-and-non-informative-values",level:3},{value:"c. Filtering Numeric-only Answers",id:"c-filtering-numeric-only-answers",level:3},{value:"d. Semantic Deduplication",id:"d-semantic-deduplication",level:3},{value:"2. Chunking and Vector Embedding",id:"2-chunking-and-vector-embedding",level:2},{value:"a. Row-based Chunking",id:"a-row-based-chunking",level:3},{value:"b. Embedding with Ollama",id:"b-embedding-with-ollama",level:3},{value:"3. Vector Database Storage (ChromaDB)",id:"3-vector-database-storage-chromadb",level:2},{value:"a. Document Preparation and Storage",id:"a-document-preparation-and-storage",level:3},{value:"4. Semantic Retrieval &amp; Reranking",id:"4-semantic-retrieval--reranking",level:2},{value:"a. Query Embedding and Similarity Search",id:"a-query-embedding-and-similarity-search",level:3},{value:"b. Cosine Reranking",id:"b-cosine-reranking",level:3},{value:"5. Prompt Construction &amp; LLM Response",id:"5-prompt-construction--llm-response",level:2},{value:"a. Prompt Construction",id:"a-prompt-construction",level:3},{value:"b. LLM Inference",id:"b-llm-inference",level:3},{value:"6. FastAPI Web Application",id:"6-fastapi-web-application",level:2},{value:"a. FastAPI Setup",id:"a-fastapi-setup",level:3},{value:"b. Query Handling Endpoint",id:"b-query-handling-endpoint",level:3},{value:"c. Frontend (HTML/CSS)",id:"c-frontend-htmlcss",level:3},{value:"Summary: Advantages &amp; Innovations",id:"summary-advantages--innovations",level:2}];function c(e){const n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"technical-code-walkthrough",children:"Technical Code Walkthrough"})}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"1-data-preprocessing",children:"1. Data Preprocessing"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Purpose:"})," Prepare raw Kisan Call Centre Q&A data for high-quality semantic retrieval by cleaning, filtering, and deduplicating entries."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"a-loading-data",children:"a. Loading Data"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'data = pd.read_csv(r"C:\\Users\\amank\\Downloads\\Agri-chatbot-versions\\data\\data\\questionsv4.csv")\r\ndata.head()\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Functionality:"})," Loads the CSV containing all Q&A pairs into a DataFrame for processing."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"b-handling-missing-and-non-informative-values",children:"b. Handling Missing and Non-informative Values"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"data.isna().sum()\r\nhyphen_rows = data[data['answers'].astype(str).str.strip('-') == \"\"]\r\ndata = data[~data['answers'].astype(str).str.strip('-').eq(\"\")]\r\ncall_transferred_rows = data[data['questions'].str.contains(\"test call\", case=False, na=False)]\r\ndata = data[~data['questions'].str.contains(\"test call\", case=False, na=False)]\r\ncall_transferred_rows = data[data['answers'].str.contains(\"transfered\", case=False, na=False)]\r\ndata = data[~data['answers'].str.contains(\"transfered\", case=False, na=False)]\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Removes rows with missing or placeholder answers (e.g., ",(0,a.jsx)(n.code,{children:"--"}),")."]}),"\n",(0,a.jsxs)(n.li,{children:["Filters out administrative or test entries (e.g., ",(0,a.jsx)(n.code,{children:"test call"}),", ",(0,a.jsx)(n.code,{children:"transfered"}),")."]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["\u2705 ",(0,a.jsx)(n.strong,{children:"Advantage:"})," Ensures only relevant, informative Q&A pairs remain."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"c-filtering-numeric-only-answers",children:"c. Filtering Numeric-only Answers"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def contains_alphabet(value):\r\n    return bool(re.search(r'[a-zA-Z]', str(value)))\r\n\r\ndf_without_letters = data[~data['answers'].astype(str).apply(contains_alphabet)]\r\ndf_with_letters = data[data['answers'].astype(str).apply(contains_alphabet)]\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Separates out answers that contain no alphabetic characters (likely non-informative)."}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["\u2705 ",(0,a.jsx)(n.strong,{children:"Advantage:"})," Further improves dataset quality by removing irrelevant entries."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"d-semantic-deduplication",children:"d. Semantic Deduplication"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"df['qa_combined'] = df['questions'].str.lower().str.strip() + ' ' + df['answers'].str.lower().str.strip()\r\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\r\nmodel = SentenceTransformer('all-MiniLM-L6-v2').to(device)\r\nembeddings = model.encode(df['qa_combined'], convert_to_tensor=True, device=device, show_progress_bar=True, batch_size=512)\r\ncosine_scores = util.pytorch_cos_sim(embeddings, embeddings)\r\nto_drop = set()\r\nfor i in range(len(df)):\r\n    if i in to_drop:\r\n        continue\r\n    for j in range(i+1, len(df)):\r\n        if cosine_scores[i][j] > 0.95:\r\n            to_drop.add(j)\r\ndf_dedup = df.drop(index=list(to_drop)).reset_index(drop=True)\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Concatenates Q&A for semantic comparison."}),"\n",(0,a.jsx)(n.li,{children:"Computes embeddings using a transformer model."}),"\n",(0,a.jsx)(n.li,{children:"Removes semantically duplicate entries (cosine similarity > 0.95)."}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["\u2705 ",(0,a.jsx)(n.strong,{children:"Advantage over traditional deduplication:"})," Detects near-duplicates even if phrased differently, resulting in a more diverse and relevant dataset."]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"2-chunking-and-vector-embedding",children:"2. Chunking and Vector Embedding"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Purpose:"})," Transform each Q&A pair into a vector embedding, ready for semantic search."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"a-row-based-chunking",children:"a. Row-based Chunking"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Implementation:"})," Each DataFrame row (a Q&A pair) is treated as a single document."]}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["\u2705 ",(0,a.jsx)(n.strong,{children:"Advantage:"})," Maintains semantic coherence and aligns with retrieval needs."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"b-embedding-with-ollama",children:"b. Embedding with Ollama"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class OllamaEmbeddings:\r\n    def __init__(self, client):\r\n        self.client = client\r\n    def embed_documents(self, texts):\r\n        return [self.ollama_embed(text) for text in texts]\r\n    def embed_query(self, text):\r\n        return self.ollama_embed(text)\r\n    def ollama_embed(self, text: str):\r\n        response = self.client.embeddings.create(\r\n            model='nomic-embed-text:latest',\r\n            input=text\r\n        )\r\n        return response.data[0].embedding\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Wraps embedding generation using a local Ollama server."}),"\n",(0,a.jsx)(n.li,{children:"Ensures all embeddings (documents and queries) are consistent."}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["\u2705 ",(0,a.jsx)(n.strong,{children:"Advantage:"})," Local, private, and fast; easily swappable for future models."]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"3-vector-database-storage-chromadb",children:"3. Vector Database Storage (ChromaDB)"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Purpose:"})," Persistently store document embeddings for fast, scalable semantic search."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"a-document-preparation-and-storage",children:"a. Document Preparation and Storage"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class ChromaDBBuilder:\r\n    def load_csv_to_documents(self):\r\n        df = pd.read_csv(self.csv_path)\r\n        self.documents = [\r\n            Document(\r\n                page_content=f\"Question: {row['questions']}\\nAnswer: {row['answers']}\",\r\n                metadata={\"row\": i}\r\n            )\r\n            for i, row in df.iterrows()\r\n        ]\r\n    def store_documents_to_chroma(self):\r\n        db = Chroma.from_documents(\r\n            documents=self.documents,\r\n            embedding=self.embedding_function,\r\n            persist_directory=self.persist_dir\r\n        )\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Loads Q&A pairs as Document objects."}),"\n",(0,a.jsx)(n.li,{children:"Embeds and stores them in ChromaDB with metadata."}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["\u2705 ",(0,a.jsx)(n.strong,{children:"Advantage:"})," Ensures persistence (no need to re-embed after restart). Fast similarity search and easy integration with LangChain."]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"4-semantic-retrieval--reranking",children:"4. Semantic Retrieval & Reranking"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Purpose:"})," Retrieve the most relevant Q&A pairs for a user\u2019s query using semantic similarity."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"a-query-embedding-and-similarity-search",children:"a. Query Embedding and Similarity Search"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class ChromaQueryHandler:\r\n    def get_answer(self, question: str) -> str:\r\n        raw_results = self.db.similarity_search_with_score(question, k=10)\r\n        relevant_docs = self.rerank_documents(question, raw_results)\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Embeds the user\u2019s query."}),"\n",(0,a.jsx)(n.li,{children:"Retrieves top-k (e.g., 10) most similar documents from ChromaDB."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"b-cosine-reranking",children:"b. Cosine Reranking"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def rerank_documents(self, question, results, top_k=5):\r\n    query_embedding = self.embedding_function.embed_query(question)\r\n    reranked = sorted(\r\n        results,\r\n        key=lambda x: self.cosine_sim(query_embedding,\r\n                                      self.embedding_function.embed_query(x[0].page_content)),\r\n        reverse=True\r\n    )\r\n    return [doc.page_content for doc, _ in reranked[:top_k]]\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Further reranks the retrieved documents using cosine similarity."}),"\n",(0,a.jsx)(n.li,{children:"Selects the top 5 for prompt context."}),"\n"]}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["\u2705 ",(0,a.jsx)(n.strong,{children:"Advantage:"})," Balances recall (broad search) and precision (fine reranking). Filters out less relevant results, improving LLM response quality."]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"5-prompt-construction--llm-response",children:"5. Prompt Construction & LLM Response"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Purpose:"})," Combine retrieved context and user query into a prompt for the LLM, then generate a factual, context-grounded answer."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"a-prompt-construction",children:"a. Prompt Construction"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"def construct_prompt(self, context, question):\r\n    return self.PROMPT_TEMPLATE.format(context=context, question=question)\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Inserts the top 5 Q&A contexts and the user\u2019s question into a structured prompt."}),"\n",(0,a.jsx)(n.li,{children:"Instructs the LLM to only use provided context, avoid hallucinations, and provide fallback if insufficient information."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"b-llm-inference",children:"b. LLM Inference"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"response = self.client.chat.completions.create(\r\n    model=self.model_name,\r\n    messages=messages,\r\n    temperature=0.3\r\n)\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Sends the prompt to the locally hosted LLM (e.g., gemma3:27b via Ollama)."}),"\n",(0,a.jsx)(n.li,{children:"Receives and returns the synthesized answer."}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"6-fastapi-web-application",children:"6. FastAPI Web Application"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Purpose:"})," Provide a user-friendly web interface for interacting with the chatbot."]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"a-fastapi-setup",children:"a. FastAPI Setup"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'app = FastAPI()\r\napp.mount("/static", StaticFiles(directory="static"), name="static")\r\ntemplates = Jinja2Templates(directory="templates")\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Sets up static file serving and Jinja2 templating for HTML rendering."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"b-query-handling-endpoint",children:"b. Query Handling Endpoint"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'@app.post("/query", response_class=HTMLResponse)\r\nasync def query(request: Request, question: str = Form(...)):\r\n    raw_answer = query_handler.get_answer(question)\r\n    html_answer = markdown.markdown(answer_only, extensions=["extra", "nl2br"])\r\n    return templates.TemplateResponse("index.html", {\r\n        "request": request,\r\n        "result": html_answer,\r\n        "question": question\r\n    })\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Receives user queries from the web form."}),"\n",(0,a.jsx)(n.li,{children:"Calls the retrieval and LLM pipeline."}),"\n",(0,a.jsx)(n.li,{children:"Renders the answer (converted from markdown to HTML) on the webpage."}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"c-frontend-htmlcss",children:"c. Frontend (HTML/CSS)"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"index.html:"})," Provides a clean, responsive user interface for question submission and answer display."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"style.css:"})," Ensures a professional, readable, and visually appealing UI."]}),"\n"]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsx)(n.h2,{id:"summary-advantages--innovations",children:"Summary: Advantages & Innovations"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Semantic Deduplication:"})," Removes redundant knowledge, improving retrieval diversity."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Row-based Chunking:"})," Ensures each Q&A pair is contextually coherent and maximally useful."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Local Embedding & LLM:"})," Privacy, speed, and flexibility; no reliance on third-party APIs."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"ChromaDB Integration:"})," Fast, persistent, and scalable vector storage."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Cosine Reranking:"})," Increases answer relevance and precision."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Structured Prompting:"})," Reduces hallucinations, ensures factual, context-based answers."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Modern Web UI:"})," FastAPI + Jinja2 + Markdown for a seamless user experience."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>l});var r=s(6540);const a={},t=r.createContext(a);function i(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);